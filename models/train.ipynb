{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# requirimentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install gcsfs datasets\n",
    "!pip install --upgrade sentence-transformers\n",
    "!pip install --upgrade transformers\n",
    "!pip install unidecode\n",
    "!python -m spacy download pt_core_news_md\n",
    "!pip install --upgrade torch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from sentence_transformers import (\n",
    "    SentenceTransformer,\n",
    "    InputExample,\n",
    "    SentenceTransformerTrainer,\n",
    "    SentenceTransformerTrainingArguments,\n",
    ")\n",
    "from sentence_transformers.losses import CosineSimilarityLoss\n",
    "from sentence_transformers.losses import MultipleNegativesRankingLoss\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from sentence_transformers.evaluation import EmbeddingSimilarityEvaluator\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "\n",
    "\n",
    "model = SentenceTransformer(\"neuralmind/bert-large-portuguese-cased\")\n",
    "\n",
    "\n",
    "torch.manual_seed(42)\n",
    "\n",
    "csv_path = \"/content/base_de_dados_binarios_lema.csv\"\n",
    "data = pd.read_csv(csv_path)\n",
    "sample_weights = compute_sample_weight(class_weight=\"balanced\", y=data[\"Label\"])\n",
    "train_examples = [\n",
    "    InputExample(texts=[row[\"Text1\"], row[\"Text2\"]], label=float(row[\"Label\"]))\n",
    "    for _, row in data.iterrows()\n",
    "]\n",
    "\n",
    "dataset = Dataset.from_dict({\n",
    "    \"text1\": [example.texts[0] for example in train_examples],\n",
    "    \"text2\": [example.texts[1] for example in train_examples],\n",
    "    \"label\": [example.label for example in train_examples],\n",
    "})\n",
    "\n",
    "split = dataset.train_test_split(test_size=0.1)\n",
    "train_dataset = split[\"train\"]\n",
    "eval_dataset = split[\"test\"]\n",
    "\n",
    "loss = CosineSimilarityLoss(model)\n",
    "\n",
    "args = SentenceTransformerTrainingArguments(\n",
    "    output_dir=\"models/bert-ptbr-regression\",\n",
    "    num_train_epochs=5,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    learning_rate=1e-5,\n",
    "    warmup_ratio=0.1,\n",
    "    weight_decay=0.1,\n",
    "    fp16=True,\n",
    "    logging_steps=5,\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=200,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=1000,\n",
    "    save_total_limit=2,\n",
    "    load_best_model_at_end=True,\n",
    "    run_name=\"bert-ptbr-regression\",\n",
    "    logging_dir=\"/content/logs\",\n",
    "    greater_is_better=False,\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    ")\n",
    "\n",
    "\n",
    "evaluator = EmbeddingSimilarityEvaluator(\n",
    "    sentences1=eval_dataset[\"text1\"],\n",
    "    sentences2=eval_dataset[\"text2\"],\n",
    "    scores=eval_dataset[\"label\"],\n",
    "    name=\"eval-similarity\",\n",
    ")\n",
    "\n",
    "\n",
    "trainer = SentenceTransformerTrainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    loss=loss,\n",
    "    evaluator=evaluator,\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "model.save_pretrained(\"models/acho14k15epochs\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
